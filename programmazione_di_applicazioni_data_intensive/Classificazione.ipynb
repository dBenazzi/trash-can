{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dBenazzi/trash-can/blob/main/programmazione_di_applicazioni_data_intensive/Classificazione.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Stw5747ucc1"
      },
      "source": [
        "# Laboratorio: Classificazione\n",
        "\n",
        "**Programmazione di Applicazioni Data Intensive**  \n",
        "Laurea in Ingegneria e Scienze Informatiche  \n",
        "DISI - Università di Bologna, Cesena\n",
        "\n",
        "Proff. Gianluca Moro, Roberto Pasolini  \n",
        "nome.cognome@unibo.it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_TVhSmoucc_"
      },
      "outputs": [],
      "source": [
        "# setup e test librerie\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEbhPFRjucdE"
      },
      "source": [
        "## Classificazione\n",
        "\n",
        "- Nei problemi visti finora di _regressione_, l'obiettivo è prevedere il valore di una variabile _continua_\n",
        "  - una quantità di energia consumata, il prezzo di una casa, ...\n",
        "- Nei problemi di **_classificazione_** l'obiettivo generale è invece, per ogni osservazione, **distinguere uno di due o più casi (_classi_) possibili**\n",
        "- Come per la regressione, un modello di classificazione va addestrato su esempi già correttamente classificati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oleIM9yeucdF"
      },
      "source": [
        "## Caso di studio: Diagnostica per immagini\n",
        "\n",
        "- Data un'immagine di cellule tumorali estratte da un paziente, si vogliono classificare queste come benigne o maligne\n",
        "- Da ciascuna cellula possono essere estratte delle caratteristiche\n",
        "  - dimensione, concavità, consistenza, ...\n",
        "- Dall'immagine intera possiamo estrarre statistiche su ciascuna di queste caratteristiche\n",
        "- Vogliamo addestrare un modello a classificare ciascuna immagine sulla base di queste caratteristiche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mM1oWUJucdH"
      },
      "source": [
        "_Immagini da cui sono estratte le righe 92751 e 927241 del dataset_\n",
        "\n",
        "![immagine cellule](http://web.archive.org/web/19970511062136/http://www.cs.wisc.edu/~street/images/92_751.gif)\n",
        "![immagine cellule](http://web.archive.org/web/19970511062136/http://www.cs.wisc.edu/~street/images/92_7241.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT2qrtpUucdI"
      },
      "source": [
        "- Utilizziamo il [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29), in cui ogni osservazione contiene le caratteristiche estratte da un'immagine\n",
        "- Con `read_csv` possiamo importare il dataset direttamente in un frame pandas dato il suo URL\n",
        "  - con `header=None` specifichiamo l'assenza di una riga header\n",
        "  - la prima colonna contiene un ID univoco per osservazione, la impostiamo come indice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTSPWi2FucdK"
      },
      "outputs": [],
      "source": [
        "BCWDS_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "bcwds = pd.read_csv(BCWDS_URL, header=None, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRI57MNBucdM"
      },
      "outputs": [],
      "source": [
        "bcwds.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW6BgxIxucdP"
      },
      "source": [
        "- La prima colonna dei dati indica la classificazione delle cellule nell'immagine\n",
        "  - M = maligne, B = benigne\n",
        "- Le altre 30 colonne corrispondono alle variabili estratte dalle immagini\n",
        "- Da ogni cellula in ogni immagine sono state estratte le seguenti caratteristiche\n",
        "  - si veda la pagina del dataset per il significato di ciascuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HraX1i3eucdR"
      },
      "outputs": [],
      "source": [
        "cell_features = [\"radius\",     \"texture\",\n",
        "                 \"perimeter\",  \"area\",\n",
        "                 \"smoothness\", \"compactness\",\n",
        "                 \"concavity\",  \"concave_pts\",\n",
        "                 \"symmetry\",   \"fractal_dim\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Imv-ggucdS"
      },
      "source": [
        "- Sull'insieme delle cellule sono estratte tre statistiche per ciascuna caratteristica: la media, la deviazione standard e la media dei tre valori più alti (\"worst\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4UUr6s7ucdT"
      },
      "outputs": [],
      "source": [
        "stats = [\"mean\", \"std\", \"worst\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRDGvF2XucdU"
      },
      "source": [
        "- Assegniamo i nomi alle colonne del frame, generandoli dalle due liste sopra con due cicli innestati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z90MXoMsucde"
      },
      "outputs": [],
      "source": [
        "bcwds.columns = [\"diagnosis\"] + [f\"{stat}_{feat}\" for stat in stats for feat in cell_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXc7NCNucdf"
      },
      "source": [
        "- Abbiamo così il frame con nomi leggibili per le colonne\n",
        "- Di default pandas visualizza al massimo 20 colonne (prime 10 e ultime 10): il seguente comando aumenta tale limite\n",
        "  - ci sono [varie altre opzioni](https://pandas.pydata.org/docs/user_guide/options.html) impostabili per la visualizzazione dei frame, ad es. `max_rows` per il numero di righe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLlFS3niucdg"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_columns = 31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTsVDretucdh"
      },
      "outputs": [],
      "source": [
        "bcwds.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGFZDut9ucdi"
      },
      "source": [
        "## Esercizio 1: Analisi esplorativa\n",
        "\n",
        "- **(1a)** Stampare il numero di valori \"M\" e \"B\" della variabile `diagnosis`\n",
        "- **(1b)** Rappresentare la distribuzione di valori di `diagnosis` in un diagramma a torta\n",
        "- **(1c)** Visualizzare le statistiche principali (media, dev. standard, ...) delle 10 variabili `mean_*`\n",
        "  - si trovano dalla 2ᵃ all'11ᵃ colonna del frame\n",
        "- **(1d)** Rappresentare la distribuzione di valori di `mean_area` in un'istogramma a 20 intervalli\n",
        "- **(1e)** Rappresentare la distribuzione congiunta di `mean_area` e `mean_concave_pts` in un grafico a dispersione"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bcwds[\"diagnosis\"].value_counts()"
      ],
      "metadata": {
        "id": "oAd7YORjzC2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b\n",
        "bcwds[\"diagnosis\"].value_counts().plot.pie()"
      ],
      "metadata": {
        "id": "pnHk5hTR0JFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c\n",
        "bcwds[2:12].describe()"
      ],
      "metadata": {
        "id": "Cxq3XwiF0QdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d\n",
        "bcwds[\"mean_area\"].plot.hist(bins=20)"
      ],
      "metadata": {
        "id": "ZEKGjeaw0c5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# e\n",
        "bcwds.plot.scatter(\"mean_area\", \"mean_concave_pts\");"
      ],
      "metadata": {
        "id": "lQ8mhxyh09A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4t28_Qvucdj"
      },
      "source": [
        "## Distribuzione valori suddivisi per classi\n",
        "\n",
        "- In un problema di classificazione, è utile visualizzare quanto le variabili predittive siano correlate con la classe da predire\n",
        "- Negli ultimi punti dell'esercizio abbiamo generato grafici con la distribuzione delle variabili, ignorando la classe di appartenenza\n",
        "- Vogliamo ora integrare l'informazione della classe negli stessi grafici, per valutare quanto le variabili siano utili nella predizione della classe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-kbhSy1ucdk"
      },
      "source": [
        "- Visualizziamo un'istogramma _stacked_ di `mean_area`, in cui in ogni intervallo si vede la suddivisione dei valori tra le due classi\n",
        "  - con `pivot(columns=\"diagnosis\")` sdoppiamo ciascuna colonna nel frame, suddividendo i valori relativi alle classi B e M\n",
        "  - con `[\"mean_area\"]` selezioniamo le due colonne `(\"mean_area\", *)`\n",
        "  - visualizziamole in un'istogramma, specificando `stacked=True` per far sì che le barre delle due colonne siano poste una sopra l'altra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t85_Rf4uucdk"
      },
      "outputs": [],
      "source": [
        "bcwds.pivot(columns=\"diagnosis\")[\"mean_area\"].plot.hist(bins=20, stacked=True, figsize=(12, 6));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgInKfoxucdl"
      },
      "source": [
        "- Questo grafico evidenzia ad es. che la `mean_area` è tendenzialmente bassa nei casi B e alta nei casi M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Gq5WQiucdl"
      },
      "source": [
        "- Possiamo evidenziare le classi anche nei diagrammi a dispersione con la distribuzione tra due variabili, differenziando i punti ad es. per colore\n",
        "- Definiamo in un dizionario che associ un colore a ciascuna classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8fpJe33ucdm"
      },
      "outputs": [],
      "source": [
        "diagnosis_color_map = {\"B\": \"blue\", \"M\": \"red\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngWHmfuLucdm"
      },
      "source": [
        "- Col metodo `map`, convertiamo ciascun elemento in una serie (o frame) secondo un dizionario dato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iVVUNB1ucdn"
      },
      "outputs": [],
      "source": [
        "diagnosis_colors = bcwds[\"diagnosis\"].map(diagnosis_color_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mCzNs20ucdn"
      },
      "source": [
        "- Otteniamo così una serie di valori \"red\" e \"blue\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jg7zD_bucdn"
      },
      "outputs": [],
      "source": [
        "diagnosis_colors.tail(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvOEeqBVucdo"
      },
      "source": [
        "- Usiamo questa serie come parametro `c` nel metodo `plot.scatter` per assegnare un colore differenziato ai punti del grafico a dispersione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOTZ10q1ucdo"
      },
      "outputs": [],
      "source": [
        "bcwds.plot.scatter(\"mean_area\", \"mean_concave_pts\", c=diagnosis_colors, figsize=(8, 6));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89DDTaalucdo"
      },
      "source": [
        "## Classificazione lineare\n",
        "\n",
        "- Come per la regressione, anche per la classificazione i metodi più semplici si basano su modelli con relazioni lineari tra le variabili\n",
        "- Un classificatore a due classi _lineare_ è definito da un **iperpiano** che separa lo spazio delle variabili in due _semispazi_\n",
        "  - la classe prevista per un'osservazione (un punto) dipende dal semispazio in cui si trova\n",
        "- Se consideriamo uno spazio di due variabili (un piano), questo significa in pratica tracciare una retta che separi una classe dall'altra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAC3fcnBucdp"
      },
      "source": [
        "- Consideriamo ad esempio il piano visualizzato sopra con le due variabili `mean_area` e `mean_concave_pts` e le osservazioni differenziate per classe\n",
        "- Selezioniamo i dati su cui lavorare\n",
        "  - la variabile `y` da predire è la classe: B (benigno) o M (maligno)\n",
        "  - le variabili `X` sono `mean_area` ($x_1$) e `mean_concave_pts` ($x_2$), per ora ignoriamo le altre variabili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6QQgXHeucdp"
      },
      "outputs": [],
      "source": [
        "y = bcwds[\"diagnosis\"]\n",
        "X2d = bcwds[[\"mean_area\", \"mean_concave_pts\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N6ge9LWucdq"
      },
      "source": [
        "- Suddividiamo come al solito i dati in un training set e in un validation set con la funzione `train_test_split`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuzU4WI_ucdq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X2d_train, X2d_val, y_train, y_val = train_test_split(\n",
        "    X2d, y,           # dati da suddividere\n",
        "    test_size=1/3,    # proporzione: 2/3 training, 1/3 validation\n",
        "    random_state=42   # seed per la riproducibilità\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBGQLVjhucdq"
      },
      "source": [
        "- Visualizziamo i dati di training su cui addestrare il classificatore\n",
        "  - applichiamo ad `y_train` la mappa dei colori definita sopra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds7cgjYgucdr"
      },
      "outputs": [],
      "source": [
        "X2d_train.plot.scatter(\"mean_area\", \"mean_concave_pts\", c=y_train.map(diagnosis_color_map), figsize=(8, 6));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPtda1iCucdr"
      },
      "source": [
        "- Per addestrare un classificatore lineare, dobbiamo individuare **una retta che separi i punti rossi dai punti blu**\n",
        "- In seguito, ciascuna nuova osservazione sarà classificata \"B\" (blu) o \"M\" (rossa) a seconda del lato della retta su cui si trova\n",
        "- Ipotizziamo ad esempio di utilizzare come separatore la retta descritta dall'equazione\n",
        "$$ x_2 = -0.0001\\cdot x_1+0.15 $$\n",
        "- Possiamo rappresentare la retta sovrapposta ai dati similmente a come abbiamo fatto per i modelli di regressione\n",
        "  - campioniamo una serie di valori campione per $x_1$ (essendo una retta bastano i due estremi)\n",
        "  - estraiamo i valori corrispondenti di $x_2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8JNfeLfucds"
      },
      "outputs": [],
      "source": [
        "sep_x1 = np.linspace(0, 1500, 2)\n",
        "sep_x2 = -0.0001 * sep_x1 + 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "131OgcX_ucdt"
      },
      "outputs": [],
      "source": [
        "X2d_train.plot.scatter(\"mean_area\", \"mean_concave_pts\", c=y_train.map(diagnosis_color_map), figsize=(8, 6))\n",
        "plt.plot(sep_x1, sep_x2, c=\"green\", linewidth=2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-BZRWucdu"
      },
      "source": [
        "- Assumiamo questa retta come modello di classificazione, classificando come B i punti al di sotto e come M quelli sopra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoPD5v-3ucdu"
      },
      "source": [
        "## Esercizio 2: Estrazione predizioni classificazione\n",
        "\n",
        "- Creare un array `y_pred` che indichi la classe predetta (`\"M\"` o `\"B\"`) per ciascuna osservazione del validation set `X2d_val`\n",
        "- Consiglio: servirsi della funzione `np.where(B, xt, xf)`, che dato un array (o serie) booleano `B` ne restituisce uno di pari lunghezza con i valori `xt` e `xf` al posto di `True` e `False`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p3XWZflucdv"
      },
      "outputs": [],
      "source": [
        "X2d_pred = -0.0001 * X2d_val[\"mean_area\"] + 0.15\n",
        "y_pred = np.where(X2d_val[\"mean_concave_pts\"] - X2d_pred > 0, \"M\", \"B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIxdmW-nucdv"
      },
      "source": [
        "## Accuratezza delle predizioni\n",
        "\n",
        "- Per confrontare diversi classificatori, vogliamo una misura quantitativa della loro bontà\n",
        "- Nella predizione di valori continui (regressione), possiamo valutare un modello in base a quanto ciascun valore predetto si avvicini a quello reale\n",
        "  - questo è misurato con metriche quali ad es. MSE o R²\n",
        "- Nella classificazione, possiamo valutare direttamente se le classi predette coincidano o meno con quelle reali\n",
        "- Definiamo come **accuratezza** la percentuale di osservazioni del validation set di cui il modello predice correttamente la classe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFgghqvPucdw"
      },
      "source": [
        "## Esercizio 3: Calcolo dell'accuratezza\n",
        "\n",
        "- **(3a)** Estrarre un array booleano `correct_class` che indichi per quali osservazioni del validation set la classe indicata in `y_pred` è corretta\n",
        "- **(3b)** Da questo calcolare l'accuratezza, ovvero la percentuale di classificazioni corrette"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_class = y_pred == y_val "
      ],
      "metadata": {
        "id": "2FMkVIK-9Ocz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_class.mean()"
      ],
      "metadata": {
        "id": "ThKIK00K9fK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDyyffe3ucdx"
      },
      "source": [
        "## Modelli di classificazione lineari\n",
        "\n",
        "- Abbiamo validato un modello di classificazione individuato \"ad occhio\", vediamo ora come addestrarne uno in modo automatico\n",
        "- Un modello di classificazione lineare a $n$ variabili $x_1,\\ldots,x_n$ consiste in generale nell'individuare un iperpiano di classificazione descritto dall'equazione:\n",
        "$$ w_1\\cdot x_1+\\ldots+w_n\\cdot x_n+b = 0 $$\n",
        "- In forma vettoriale:\n",
        "$$ \\mathbf{w}\\cdot\\mathbf{x}+b = 0 $$\n",
        "- L'addestramento del modello consiste nel determinare valori ottimali per il vettore $\\mathbf{w}$ (_weights_, pesi) e per il termine $b$ (_bias_, distanza dell'iperpiano dall'origine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK4pxZT5ucdy"
      },
      "source": [
        "## Perceptron\n",
        "\n",
        "- Il _perceptron_ è un algoritmo di apprendimento molto semplice, concettualmente simile alla discesa gradiente\n",
        "  - i parametri $\\mathbf{w}$ e $b$ sono inizializzati casualmente\n",
        "  - si itera il training set: per ogni istanza mal classificata, i parametri vengono aggiornati proporzionalmente ai valori di $\\mathbf{x}$ e ad un _learning rate_ preimpostato\n",
        "  - si possono eseguire molteplici iterazioni del training set\n",
        "- Per creare un modello perceptron, come per i modelli di regressione, iniziamo creando un'istanza della classe `Perceptron`\n",
        "  - ci sono diversi parametri impostabili per ottenere varianti (es. con regolarizzazione), ma quì non le consideriamo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhszgVpUucdz"
      },
      "source": [
        "- Prima di procedere, dato che le variabili `mean_area` e `mean_concave_pts` hanno scale molto diverse, ne effettuiamo la standardizzazione (media 0 e dev. standard 1)\n",
        "  - evitiamo per ora di utilizzare una pipeline, per analizzare più agevolmente il modello\n",
        "- Utilizziamo un filtro `StandardScaler` per ottenere gli array `X2dn_train` e `X2dn_val` con i dati in `X2d_train` e `X2d_val` standardizzati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIMZrdXxucdz"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X2dn_train = scaler.fit_transform(X2d_train)\n",
        "X2dn_val = scaler.transform(X2d_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzunlDRQucd0"
      },
      "source": [
        "- Visualizziamo in un grafico a dispersione i dati standardizzati `X2dn_train` con classi differenziate\n",
        "  - si ottiene una figura identica a quella dei dati non standardizzati, con solamente gli intervalli degli assi cambiati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc2cfCm0ucd0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X2dn_train[:, 0], X2dn_train[:, 1], c=y_train.map(diagnosis_color_map));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv8fc4u_ucd1"
      },
      "source": [
        "- Creiamo un modello `Perceptron`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyRyMdS9ucd2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "model = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah_3_3OSucd2"
      },
      "source": [
        "- Addestriamo il modello sul training set standardizzato\n",
        "  - come nei modelli di regressione, passiamo separatamente i valori delle variabili predittive (X) e quelli della variabile da predire (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfzPMJqEucd3"
      },
      "outputs": [],
      "source": [
        "model.fit(X2dn_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZjGAFhyucd3"
      },
      "source": [
        "- Una volta addestrato il modello, possiamo trovare i valori dei pesi $\\mathbf{w}$ e del bias $b$ rispettivamente negli attributi `coef_[0]` e `intercept_[0]`\n",
        "  - lo `[0]` si riferisce al primo iperpiano, in questo caso è l'unico, in un modello a più di due classi sarebbero molteplici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WULnYp35ucd4"
      },
      "outputs": [],
      "source": [
        "model.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bRhOJTSucd4"
      },
      "outputs": [],
      "source": [
        "model.intercept_[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1NeJQxHucd5"
      },
      "source": [
        "- Ad esempio questi coefficienti indicano che l'iperpiano individuato dal modello è descritto dall'equazione\n",
        "$$ 0.558x_1+1.686x_2-1 = 0 $$\n",
        "- L'attributo `classes_` mostra le classi riconosciute dal classificatore\n",
        "  - la prima è quella a cui sono assegnati i punti sotto la retta, la seconda quella a cui sono assegnati i punti sopra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V9_Wz6nucd6"
      },
      "outputs": [],
      "source": [
        "model.classes_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af8NxWyxucd6"
      },
      "source": [
        "- Per visualizzare la retta del modello...\n",
        "$$ w_1\\cdot x_1+w_2\\cdot x_2+b = 0 $$\n",
        "- ...la esprimiamo nella forma $x_2=\\ldots$\n",
        "$$ x_2 = -\\frac{w_1}{w_2}\\cdot x_1-\\frac{b}{w_2} $$\n",
        "- Implementiamo una funzione `separator_2d` in modo che, dato un modello e un array di valori $x_1$, restituisca l'array di corrispondenti valori $x_2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC-OAGwtucd7"
      },
      "outputs": [],
      "source": [
        "def separator_2d(model, x1):\n",
        "    # ricaviamo w e b dal modello\n",
        "    w = model.coef_[0]\n",
        "    b = model.intercept_[0]\n",
        "    # riportiamo in NumPy la formula sopra\n",
        "    return -x1 * w[0] / w[1] - b / w[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8e6gu1Aucd7"
      },
      "source": [
        "- Creiamo una funzione per visualizzare la retta del modello sovrapposta al grafico a dispersione dei dati, simile a quella che utilizzavamo nella regressione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LMf8PoSucd8"
      },
      "outputs": [],
      "source": [
        "def plot_separator_on_data(X, y, model=None):\n",
        "    X = np.array(X)\n",
        "    colors = pd.Series(y).map(diagnosis_color_map)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=colors)\n",
        "    if model is not None:\n",
        "        xlim, ylim = plt.xlim(), plt.ylim()\n",
        "        sep_x = np.linspace(*xlim, 2)\n",
        "        sep_y = separator_2d(model, sep_x)\n",
        "        plt.plot(sep_x, sep_y, c=\"green\", linewidth=2)\n",
        "        plt.xlim(xlim); plt.ylim(ylim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpkZi9jWucd9"
      },
      "source": [
        "- Visualizziamo la retta di separazione sovrapposta al validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB9UJ_h7uceB"
      },
      "outputs": [],
      "source": [
        "plot_separator_on_data(X2dn_val, y_val, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzPtcplxuceC"
      },
      "source": [
        "- Dal modello addestrato possiamo ottenere le predizioni per una o più osservazioni con `predict`\n",
        "  - otteniamo ad esempio le predizioni per i primi 3 elementi del validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJN8keMOuceC"
      },
      "outputs": [],
      "source": [
        "model.predict(X2dn_val[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDMYB4mYuceD"
      },
      "source": [
        "- L'accuratezza definita sopra è la metrica predefinita per i modelli di classificazione: possiamo calcolarla col metodo `score`\n",
        "  - come per calcolare R² nei modelli di regressione, passiamo X e y del validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdfR1K91uceE"
      },
      "outputs": [],
      "source": [
        "model.score(X2dn_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCdbUOBquceF"
      },
      "source": [
        "- Il modello classifica correttamente quasi il 90\\% delle istanze del validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9tJiXjFuceF"
      },
      "source": [
        "## Matrice di confusione, precision e recall\n",
        "\n",
        "- Oltre all'accuratezza come percentuale di classificazioni corrette, esistono altri modi per valutare l'accuratezza di un classificatore\n",
        "  - particolarmente utili in caso di sbilanciamento tra le classi, per cui l'accuratezza può non essere un indicatore affidabile\n",
        "- Confrontando le classi predette da un classificatore su un set di dati con quelle reali, possiamo ottenere una **_matrice di confusione_**\n",
        "- Ogni cella in riga i e colonna j indica quanti esempi della classe i-esima sono stati etichettati dal classificatore come di classe j-esima\n",
        "  - lungo la diagonale (i=j) abbiamo quindi le quantità di classificazioni corrette, al di fuori abbiamo invece le quantità di errori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxMeQ3u0uceG"
      },
      "source": [
        "- Otteniamo la matrice col metodo `confusion_matrix`, passando i vettori di classi reali e predette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtY2BHQXuceG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = model.predict(X2dn_val)\n",
        "cm = confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzG1ow98uceH"
      },
      "source": [
        "- Otteniamo la matrice in forma di array NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTCexK29uceH"
      },
      "outputs": [],
      "source": [
        "cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQscV9uTuceI"
      },
      "source": [
        "- Per maggiore chiarezza, inseriamo i valori in un frame etichettando righe e colonne con i nomi delle classi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czS5m7UXuceI"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(cm, index=model.classes_, columns=model.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MR4f2FuceJ"
      },
      "source": [
        "- La matrice ad esempio ci indica che, di 68 esempi di immagini di cellule maligne (seconda riga) presenti nel validation set\n",
        "  - 48 sono state correttamente etichettate come tali\n",
        "  - 20 sono state erroneamente etichettate come benigne\n",
        "- L'accuratezza si può ottenere dalla matrice di confusione come somma dei valori nella diagonale divisa per la somma complessiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZekbaaluceJ"
      },
      "outputs": [],
      "source": [
        "cm.diagonal().sum() / cm.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpWPYCEIuceK"
      },
      "source": [
        "- Dalla sola matrice di confusione possiamo ricavare altre misure di performance importanti\n",
        "- Presa una classe di riferimento, ad es. \"M\" (cellule maligne), la **_precision_** indica la percentuale di esempi classificati come \"M\" che sono realmente tali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3sr8RUBuceL"
      },
      "outputs": [],
      "source": [
        "#        quante istanze del validation set sono PREDETTE \"M\"\n",
        "#                          ^^^^^^^^^^^^^^\n",
        "malignant_prc = cm[1, 1] / cm[:, 1].sum()\n",
        "malignant_prc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJa3QescuceL"
      },
      "source": [
        "- Di contro, la **_recall_** indica la percentuale di esempi realmente di classe \"M\" che sono stati rilevati essere tali dal modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAizhKveuceM"
      },
      "outputs": [],
      "source": [
        "#        quante istanze del validation set sono REALMENTE \"M\"\n",
        "#                          ^^^^^^^^^^^^^^\n",
        "malignant_rec = cm[1, 1] / cm[1, :].sum()\n",
        "malignant_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkcGHV6JuceM"
      },
      "source": [
        "- Precision e recall sono quindi due indicatori complementari della bontà di un modello\n",
        "- Generalmente, tarando il modello per migliorarne uno, l'altro peggiora\n",
        "- Come misura unica della performance di un modello è spesso usata quindi la **_F1-measure_**, ovvero la media armonica tra precision e recall\n",
        "$$ F_1 = \\frac{2\\cdot P\\cdot R}{P+R} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipq5SEUuuceM"
      },
      "outputs": [],
      "source": [
        "2 * malignant_prc * malignant_rec / (malignant_prc + malignant_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrcmmtjRuceN"
      },
      "source": [
        "- Per calcolare direttamente tali misure, scikit-learn fornisce le funzioni `precision_score`, `recall_score` e `f1_score`\n",
        "  - col parametro `pos_label` si indica la classe di riferimento\n",
        "  - si può in alternativa ottenere un vettore di punteggi per tutte le classi (`average=None`) o la loro media (`average=\"macro\"`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2cv8cGWuceN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRAg2lGWuceN"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, pos_label=\"M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPrGrXKauceO"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, pos_label=\"M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VL1lwFPuceO"
      },
      "outputs": [],
      "source": [
        "f1_score(y_val, y_pred, average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ueYLJ9IuceO"
      },
      "outputs": [],
      "source": [
        "f1_score(y_val, y_pred, average=\"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpygtULDuceP"
      },
      "source": [
        "## Regressione Logistica\n",
        "\n",
        "- La regressione _logistica_ è un modello di classificazione binaria basato sulla regressione lineare\n",
        "- Sia data una variabile y pari a 1 per gli esempi di una classe (positiva) e -1 per quelli dell'altra (negativa), si minimizza la funzione\n",
        "$$ \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) $$\n",
        "- Per addestrare tale modello, creiamo un oggetto `LogisticRegression`\n",
        "  - `random_state` indica il seed per la casualità usato nell'addestramento\n",
        "  - `solver` indica quale implementazione utilizzare tra [diverse disponibili](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) per l'addestramento, `\"saga\"` è l'unica che supporta tutte le opzioni per la regolarizzazione (che vediamo sotto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwu6CmCbuceP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver=\"saga\", random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8CovPXEuceP"
      },
      "source": [
        "- Come sopra, addestriamo il modello sui dati già standardizzati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5-6sZNIuceP"
      },
      "outputs": [],
      "source": [
        "model.fit(X2dn_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qOrAEw7uceQ"
      },
      "source": [
        "- Anche quì possiamo accedere ai parametri del modello addestrato e usarli per visualizzare il piano di separazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fQyggwmuceQ"
      },
      "outputs": [],
      "source": [
        "model.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8zCF4XmuceR"
      },
      "outputs": [],
      "source": [
        "model.intercept_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GINcQshquceR"
      },
      "outputs": [],
      "source": [
        "plot_separator_on_data(X2dn_train, y_train, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCnY0TLNuceS"
      },
      "source": [
        "- La funzione logistica del modello restituisce la probabilità di appartenenza ad una classe (quella considerata \"positiva\")\n",
        "  - sia essa p, quella per la negativa è implicitamente 1-p\n",
        "- Date delle osservazioni da classificare, possiamo ottenere per ciascuna la distribuzione di probabilità tra le classi\n",
        "  - possiamo in pratica vedere quanto il classificatore sia \"sicuro\" della classe da assegnare\n",
        "- Passiamo le osservazioni al metodo `predict_proba`, ad es. le prime 3 del validation set: otteniamo una riga per ciascuna con le probabilità delle due classi\n",
        "  - possiamo verificare l'ordine delle classi in `classes_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHi953OSuceS"
      },
      "outputs": [],
      "source": [
        "model.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al0P9U3ruceT"
      },
      "outputs": [],
      "source": [
        "model.predict_proba(X2dn_val[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De4EgUCcuceU"
      },
      "source": [
        "- Ad esempio la prima osservazione è \"B\" con probabilità 88\\%, mentre la seconda è \"M\" con probabilità 99\\%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dzXqec6uceU"
      },
      "source": [
        "- Possiamo visualizzare in un grafico i dati sovrapposti al valore di probabilità restituito dal modello nello spazio dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8d0zqxuuceV"
      },
      "outputs": [],
      "source": [
        "# estraggo un campione di 100x100 punti nel piano\n",
        "mx1, mx2 = np.meshgrid(np.linspace(-2, 5.5, 100), np.linspace(-2, 4.5, 100))\n",
        "# estraggo le probabilità della classe M per ciascun punto\n",
        "my = model.predict_proba(np.c_[mx1.ravel(), mx2.ravel()])[:, 1].reshape(mx1.shape)\n",
        "# disegno il grafico\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.contourf(mx1, mx2, my, cmap=\"summer\")\n",
        "plt.scatter(*X2dn_train.T, c=y_train.map(diagnosis_color_map))\n",
        "plt.colorbar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWgtY413uceV"
      },
      "source": [
        "## Esercizio 4: Accuratezza del modello\n",
        "\n",
        "In riferimento al modello di regressione logistica, calcolare sul validation set:\n",
        "- **(4a)** l'accuratezza del modello\n",
        "- **(4b)** la matrice di confusione\n",
        "- **(4c)** la F1-measure relativa alla classe \"M\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X2dn_val, y_val)\n",
        "y_pred = model.predict(X2dn_val)"
      ],
      "metadata": {
        "id": "jU3uca9PGlMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "pd.DataFrame(conf_matrix, index=model.classes_, columns=model.classes_)"
      ],
      "metadata": {
        "id": "BICKQxoCG2pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_val, y_pred, pos_label=\"M\")"
      ],
      "metadata": {
        "id": "pFYFlxLVHK1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADeDbn9uceW"
      },
      "source": [
        "## Regolarizzazione\n",
        "\n",
        "- Anche nella regressione logistica possiamo applicare le tecniche di regolarizzazione viste nell'analisi di regressione\n",
        "- Di default nella classe `LogisticRegression` viene applicata la regolarizzazione L2, che mantiene limitati i pesi in $\\mathbf{w}$\n",
        "  - questo impedisce che a singole variabili siano dati pesi molto grandi\n",
        "- In `LogisticRegression` è possibile impostare un parametro `C`, che è il **reciproco** del peso della regolarizzazione (il parametro `alpha` visto in altre classi)\n",
        "  - `C` è il _costo_ assegnato alle classificazioni sbagliate nella funzione d'errore da minimizzare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF4pMyBnuceW"
      },
      "source": [
        "- Confrontiamo ad esempio tre modelli\n",
        "  - il `model` addestrato sopra con `C=1` (default)\n",
        "  - `model_high_C` con `C=1000` (scarsa regolarizzazione)\n",
        "  - `model_low_C` con `C=0.001` (regolarizzazione intensa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8jytYYFuceX"
      },
      "outputs": [],
      "source": [
        "model_high_C = LogisticRegression(solver=\"saga\", random_state=42, C=10000)\n",
        "model_low_C = LogisticRegression(solver=\"saga\", random_state=42, C=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4uh1qNquceX"
      },
      "source": [
        "- Addestriamo i due nuovi modelli sugli stessi dati a due variabili usati sopra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tGlb1KEuceY"
      },
      "outputs": [],
      "source": [
        "model_high_C.fit(X2dn_train, y_train)\n",
        "model_low_C.fit(X2dn_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmMdXP1SuceZ"
      },
      "source": [
        "- Mettiamo a confronto i parametri dei tre modelli addestrati\n",
        "  - creiamo una funzione per estrarli in forma di serie e la utilizziamo per costruire un frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT4gBTPVuceZ"
      },
      "outputs": [],
      "source": [
        "def params(model):\n",
        "    return pd.Series(list(model.coef_[0]) + [model.intercept_[0]],\n",
        "                     index=[\"w1\", \"w2\", \"b\"])\n",
        "models = {\"low_C\": model_low_C, \"mid_C\": model, \"high_C\": model_high_C}\n",
        "pd.DataFrame({name: params(model) for name, model in models.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9NR1sqfucea"
      },
      "source": [
        "- Si può notare che i pesi sono più alti per valori alti di C\n",
        "- Mettendo a confronto le rette dei tre modelli si può notare che, al calare di C, la retta tende ad avere un'inclinazione di (-)45°, in quanto w1 e w2 tendono ad eguagliarsi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTPFiL03ucea"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(*X2dn_train.T, c=y_train.map(diagnosis_color_map))\n",
        "xlim, ylim = plt.xlim(), plt.ylim()\n",
        "sep_x = np.linspace(*xlim, 2)\n",
        "sep_y_hc = separator_2d(model_high_C, sep_x)\n",
        "sep_y_mc = separator_2d(model, sep_x)\n",
        "sep_y_lc = separator_2d(model_low_C, sep_x)\n",
        "plt.plot(sep_x, sep_y_hc)\n",
        "plt.plot(sep_x, sep_y_mc)\n",
        "plt.plot(sep_x, sep_y_lc)\n",
        "plt.legend([\"Dati\", \"C=10000\", \"C=1\", \"C=0.01\"])\n",
        "plt.xlim(xlim); plt.ylim(ylim);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxVwB3o2uceb"
      },
      "source": [
        "- `LogisticRegression` supporta anche la regolarizzazione L1, che permette di azzerare i pesi delle variabili meno significative\n",
        "- Possiamo applicarla al posto della L2 specificando `penalty=\"l1\"`\n",
        "- Addestriamo ad esempio un modello con regolarizzazione L1 e C basso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AfrbRPuceb"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver=\"saga\", random_state=42, penalty=\"l1\", C=0.01)\n",
        "model.fit(X2dn_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmC7Ofiducec"
      },
      "source": [
        "- Vediamone i parametri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYARCUUQucec"
      },
      "outputs": [],
      "source": [
        "model.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGKYxmituced"
      },
      "outputs": [],
      "source": [
        "model.intercept_[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjGoP-TQucee"
      },
      "source": [
        "- Il peso di una delle due variabili ($x_1$) è stato annullato per via della forte regolarizzazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqFk8L6oucee"
      },
      "source": [
        "- In pratica la retta individuata dal modello è parallela all'asse $x_1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffr0bc0hucef"
      },
      "outputs": [],
      "source": [
        "plot_separator_on_data(X2dn_train, y_train, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3HnJBv4ucef"
      },
      "source": [
        "- Possiamo infine indicare `penalty=\"elasticnet\"` per applicare entrambe le tecniche di regolarizzazione\n",
        "  - con `C` si regola il peso complessivo dei due termini di regolarizzazione\n",
        "  - possiamo decidere la proporzione tra le due tramite il parametro `l1_ratio`, funzionante come nel modello di regressione `ElasticNet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FYCEHknuceg"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(\n",
        "    solver=\"saga\", random_state=42,\n",
        "    penalty=\"elasticnet\", C=0.1, l1_ratio=0.2)\n",
        "model.fit(X2dn_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKt8eVvNuceg"
      },
      "source": [
        "- In questo dataset relativamente semplice non si apprezzano particolari differenze nell'accuratezza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6drM70yzuceh"
      },
      "outputs": [],
      "source": [
        "model.score(X2dn_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5K_tuBpuceh"
      },
      "source": [
        "- È anche possibile disabilitare completamente la regolarizzazione con `penalty=\"none\"`, in tal caso il parametro `C` è ininfluente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7prrJY5yucei"
      },
      "source": [
        "## Cross-validation su classificazione\n",
        "\n",
        "- Abbiamo già visto la cross validation a k fold per la validazione di un modello\n",
        "  - ciascun 1/k dei dati è testato su un modello addestrato sui restanti\n",
        "- Dovendo addestrare un modello a riconoscere delle classi, è opportuno che le proporzioni di ciascuna classe nei fold siano uguali\n",
        "- `StratifiedKFold` è una variante di `KFold` che garantisce uguale distribuzione delle classi tra un fold e l'altro\n",
        "  - le opzioni impostabili sono le stesse (numero di fold e casualità)\n",
        "- Per confronto, creiamo sia uno splitter `KFold` che uno `StratifiedKFold` con stessi parametri (3 fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK1kseuDucei"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "kf = KFold(3, shuffle=True, random_state=42)\n",
        "skf = StratifiedKFold(3, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "571bl5Jmucej"
      },
      "source": [
        "- Confrontando le distribuzioni delle classi nei validation set dei 3 fold, vediamo che con `StratifiedKFold` sono eque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzYL6XRwucej"
      },
      "outputs": [],
      "source": [
        "# KFold\n",
        "for train, val in kf.split(X2dn_train, y_train):\n",
        "    print(y_train.iloc[val].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZG_B4nCucek"
      },
      "outputs": [],
      "source": [
        "# StratifiedKFold\n",
        "for train, val in skf.split(X2dn_train, y_train):\n",
        "    print(y_train.iloc[val].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXD_I5Tyucek"
      },
      "source": [
        "## Grid search con parametri opzionali\n",
        "\n",
        "- Abbiamo visto come, data una \"griglia\" con liste di valori possibili per gli iperparametri di un modello, la grid search testi tutte le combinazioni possibili\n",
        "- Esistono però casi in cui alcuni parametri sono significativi dipendentemente dai valori di altri\n",
        "- Ad es. in `LogisticRegression` ha senso specificare `l1_ratio` solo se `penalty=\"elasticnet\"`\n",
        "- Per risolvere il problema, possiamo scomporre le combinazioni possibili su **più griglie di parametri**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRgY0X2Jucel"
      },
      "source": [
        "- Ipotizziamo ad esempio di voler testare la `LogisticRegression` con:\n",
        "  - regolarizzazione di tipo \"l2\", \"l1\" o \"elasticnet\"\n",
        "  - parametro C pari a 0.1, 1 o 10\n",
        "  - nel caso di \"elasticnet\", `l1_ratio` pari a 0.2 o 0.5\n",
        "- Il modello base è dato da:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-VMzEGkucel"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver=\"saga\", random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQj37hmbucel"
      },
      "source": [
        "- Un modo per testare tutte le combinazioni sarebbe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-if5yqxucem"
      },
      "outputs": [],
      "source": [
        "grid = {\n",
        "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"l1_ratio\": [0.2, 0.5]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAjYLajAucem"
      },
      "source": [
        "- La griglia genera un totale di 3×3×2=18 combinazioni\n",
        "- Però i casi con regolarizzazione L2 e L1 sarebbero ripetuti con due valori possibili di `l1_ratio`, che non ha alcuna influenza\n",
        "  - riceveremmo inoltre dei warning perché impostiamo inutilmente il parametro `l1_ratio`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uamJen-ucen"
      },
      "source": [
        "- L'alternativa è scomporre i casi da provare in due griglie:\n",
        "  - una con regolarizzazione L2 e L1 senza specificare `l1_ratio`\n",
        "  - una con elasticnet specificando i valori possibili di `l1_ratio`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-kiO05sucen"
      },
      "outputs": [],
      "source": [
        "grid = [\n",
        "    {\n",
        "        \"penalty\": [\"l2\", \"l1\"],\n",
        "        \"C\": [0.1, 1, 10]\n",
        "    },\n",
        "    {\n",
        "        \"penalty\": [\"elasticnet\"],\n",
        "        \"C\": [0.1, 1, 10],\n",
        "        \"l1_ratio\": [0.2, 0.5]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pVjWi5zuceo"
      },
      "source": [
        "- La grid search testerà tutte le 2×3=6 combinazioni possibili della prima griglia e le 1×3×2=6 combinazioni possibili della seconda, per un totale di 12 configurazioni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsYfw9nKuceo"
      },
      "source": [
        "- Definiamo la grid search, specificando il modello, la lista di griglie e lo splitter per la cross-validation (usiamo lo `StratifiedKFold` creato sopra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AttCAGoUuceo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "gs = GridSearchCV(model, grid, cv=skf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ygXPeTucep"
      },
      "source": [
        "- Effettuiamo quindi la ricerca sui dati usati finora per il training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbvWhgWguces"
      },
      "outputs": [],
      "source": [
        "gs.fit(X2dn_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P07EcBQEucet"
      },
      "source": [
        "- Come al solito, possiamo verificare la migliore combinazione di iperparametri...\n",
        "  - la metrica di riferimento di default è l'accuratezza, cioè la percentuale di classificazioni corrette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IidORxdQucet"
      },
      "outputs": [],
      "source": [
        "gs.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDPCL3ouceu"
      },
      "source": [
        "- ...e vedere tutti i dettagli, ad es. selezionando le 5 parametrizzazioni con accuratezza migliore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7MkNJ78uceu"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\").head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieQ-2QKqucev"
      },
      "source": [
        "## Alberi decisionali per la classificazione\n",
        "\n",
        "- Abbiamo visto come utilizzare gli alberi decisionali per addestrare modelli di regressione non lineari\n",
        "- Lo stesso principio si può utilizzare per i problemi di classificazione con poche differenze\n",
        "  - così come nella regressione ogni foglia dell'albero rappresenta un diverso valore della variabile continua _y_ da predire...\n",
        "  - ...nella classificazione ogni foglia dell'albero indica una classe predetta per le istanze catturate da essa\n",
        "- Per addestrare alberi di classificazione usiamo la classe `DecisionTreeClassifier`, che accetta gli stessi iperparametri della classe `DecisionTreeRegressor` con lo stesso significato\n",
        "- Iniziamo addestrando un albero con profondità massima di 2 livelli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw41fdx1ucev"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth=2)\n",
        "model.fit(X2d_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyH5ocvJucew"
      },
      "source": [
        "- Come nella regressione, possiamo ottenere una rappresentazione degli alberi risultanti con le funzioni `export_text` e `plot_tree`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BanoXO4qucew"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "print(export_text(model, feature_names=X2d_train.columns.to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJOvxKR9ucex"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(model, feature_names=X2d_train.columns.to_list());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zmHLu3ucex"
      },
      "source": [
        "- L'albero in pratica classifica un'istanza come \"M\" se `mean_concave_pts > 0.05` e `mean_area > 515.90`\n",
        "- Creiamo come sopra una visualizzazione delle probabilità\n",
        "  - in ogni nodo è associata una distribuzione di probabilità pari a quella delle istanze di training catturate dal nodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAkpM3zgucey"
      },
      "outputs": [],
      "source": [
        "# estraggo un campione di 100x100 punti nel piano\n",
        "mx1, mx2 = np.meshgrid(np.linspace(0, 2700, 100), np.linspace(0, 0.22, 100))\n",
        "# estraggo le probabilità della classe M per ciascun punto\n",
        "my = model.predict_proba(np.c_[mx1.ravel(), mx2.ravel()])[:, 1].reshape(mx1.shape)\n",
        "# disegno il grafico\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.contourf(mx1, mx2, my, cmap=\"summer\")\n",
        "plt.scatter(*X2d_train.values.T, c=y_train.map(diagnosis_color_map))\n",
        "plt.colorbar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mj6lCLRucey"
      },
      "source": [
        "- L'accuratezza è in questo caso simile a quella degli altri modelli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQsKgGO6ucez"
      },
      "outputs": [],
      "source": [
        "model.score(X2d_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FISL36Xoucez"
      },
      "source": [
        "- Non limitando la profondità dell'albero si crea una suddivisione dello spazio dei dati molto fine, che spesso però costituisce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XSuorYAuce0"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(X2d_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA3wuUOKuce0"
      },
      "outputs": [],
      "source": [
        "model.score(X2d_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hh3a0fTuce1"
      },
      "outputs": [],
      "source": [
        "mx1, mx2 = np.meshgrid(np.linspace(0, 2700, 100), np.linspace(0, 0.22, 100))\n",
        "my = model.predict_proba(np.c_[mx1.ravel(), mx2.ravel()])[:, 1].reshape(mx1.shape)\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.contourf(mx1, mx2, my, cmap=\"summer\")\n",
        "plt.scatter(*X2d_train.values.T, c=y_train.map(diagnosis_color_map), s=3)\n",
        "plt.colorbar();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XukmU5fuce1"
      },
      "outputs": [],
      "source": [
        "# zoom su una porzione di grafico\n",
        "xlim = (400, 600)\n",
        "ylim = (0.03, 0.04)\n",
        "mx1, mx2 = np.meshgrid(np.linspace(*xlim, 200), np.linspace(*ylim, 200))\n",
        "my = model.predict_proba(np.c_[mx1.ravel(), mx2.ravel()])[:, 1].reshape(mx1.shape)\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.contourf(mx1, mx2, my, cmap=\"summer\")\n",
        "plt.scatter(*X2d_train.values.T, c=y_train.map(diagnosis_color_map), s=80)\n",
        "plt.xlim(xlim); plt.ylim(ylim)\n",
        "plt.colorbar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq0R_VAPuce2"
      },
      "source": [
        "## Esercizio 5: Addestramento sul dataset completo\n",
        "\n",
        "Effettuiamo ora esperimenti sul dataset completo con tutte le 30 variabili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYaRZoKLuce3"
      },
      "outputs": [],
      "source": [
        "X = bcwds.drop(columns=\"diagnosis\")\n",
        "y = bcwds[\"diagnosis\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK9g7O32uce3"
      },
      "source": [
        "- **(5a)** Addestrare un modello di regressione logistica con standardizzazione dei dati e regolarizzazione L1 con C=0.1 e stampare i pesi del modello etichettati con i nomi delle colonne\n",
        "  - verificare quante e quali delle 30 colonne risultano significative\n",
        "- **(5b)** Effettuare una grid search per ricercare i parametri migliori della regressione logistica sull'intero set di dati con cross-validation a 3 fold stratificati (riutilizzare l'oggetto `skf` sopra), testando tutte le configurazioni significative e stampando i dettagli delle 5 con migliore accuratezza\n",
        "  - con e senza standardizzazione dei dati\n",
        "  - con regolarizzazione \"l2\", \"l1\", \"elasticnet\" o \"none\" (ne L1 ne L2)\n",
        "  - con parametro C pari a 0.01, 0.1, 1, 10 o 100\n",
        "  - con `l1_ratio` pari a 0.2 o 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SReIsszIuce4"
      },
      "outputs": [],
      "source": [
        "# usare una pipeline per effettuare la standardizzazione\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"mdl\", LogisticRegression(solver=\"saga\", penalty=\"l1\", C=0.1))\n",
        "])\n",
        "mdl.fit(X, y)\n",
        "pd.Series(mdl.named_steps[\"mdl\"].coef_[0], index=X.columns)"
      ],
      "metadata": {
        "id": "48lffez6Mss-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = [\n",
        "    {\"scaler\": [None, StandardScaler()],\n",
        "    \"mdl__penalty\": [\"l1\", \"l2\", None],\n",
        "    \"mdl__C\": [0.01, 0.1, 1, 10, 100]},\n",
        "    {\"scaler\": [None, StandardScaler()],\n",
        "    \"mdl__penalty\": [\"elasticnet\"],\n",
        "    \"mdl__C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \"mdl__l1_ratio\": [0.2, 0.5]}\n",
        "]\n",
        "gs = GridSearchCV(mdl, grid, cv=skf)\n",
        "gs.fit(X, y)"
      ],
      "metadata": {
        "id": "VoVCLcrXRf1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(gs.cv_results_).sort_values(\"rank_test_score\").head(5)"
      ],
      "metadata": {
        "id": "v5Wt1fQ1Tn6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}